---
title: Treadmill desk observations
description: Notes relating to my use of a treadmill desk
created: 19 June 2012
tags: experiments, biology, psychology, statistics
status: finished
belief: likely
...

<!--
Treadmill data
31 inches per step, so 1 mile = 2040 steps
June 2012
16: 1.5 w=218
17: 2.88
18: 4 w=214
19: 2.85 w=213.4
20: 2.0 w=212.8
21: 3.4 w=212
22: 2 w=213.8
23-26: treadmill broken
27: 1.08 w=198.8
28: 2.45
29: 2.03 w=207.4
30 June - 03 July: treadmill broken
04: 1.66
05: 2.7 w=206.6
06: 0 w=203
07: 5 w=205
08: 2.6 w=201
-->
<!-- treadmill:
8 August 2013: 1.94miles; 9 August: 4.54mi ; 10: 1.5mi; 11: 2.67mi; 12: 4.39mi; 15: 3.33mi; 16: 1.5mi; 20: 1.66mi; 25: 1.31mi; 26: 2.27mi; 28: 2.25; 29: 1.66
14 September: 0.64mi; 15: 1.66; 24: 1.64mi 26: 2.42mi 28: 0.91mi
14 October: 0.7mi
8 November: 1.1mi; 10 Nov: 0.32mi; 11: 0.3; 13: 0.3; 14: 0.16; 29: 0.5
5 Dec: 0.49mi; 7: 0.38mi
28 January 2014: 1.26mi
10 February: 1.51mi; 15 February: 0.5mi; 25 February: 1.44mi; 27: 0.84mi; 28 February: 1.22mi
4 March: 0.68; 5 March: 0.85mi; 7 March: 1.03mi; 9 March: 0.14mi; 18 March: 1.07mi; 19 March: 0.63mi; 24 March: 0.52mi; 25 March: 0.4mi; 26 March: 0.5mi
3 April: 0.43mi; 22 April: 0.52mi; 30 April: 1.14mi
4 May: 0.9mi; 5 May: 0.94mi; 6 May: 0.98mi; 28 May: 1.27mi; 29 May: 0.9mi; 31 May: 1.13mi -->

# Sleep

In June 2012, early in the experiment, my neighbors threw out a treadmill that turned out to be easily repaired and so I set up an improvised [treadmill desk](!Wikipedia) with my laptop and a spare board. I had read about them before, had since seen a number of negative reports about being sedentary or sitting, and my physical fitness had declined markedly since leaving university (with ready access to the gym, fencing club, and Taekwondo class), so it seemed like a good thing to do. The lowest setting on the treadmill (no incline, 1MPH) was initially fairly exhausting but I improved. I started with one mile a day and moved up in a few days to 3-4 miles a day (putting me at the high end of my daily steps as recorded by my pedometer, which annoyingly I lost just 2 days before finding the treadmill); for some reason, this seemed to affect my weight, which went from 218 pounds to 214 a week later and 213 the next day. I finetuned the treadmill desk for typing on my laptop by increasing the height of the board with book supports. My productivity suffered drastically the first days, and I was concerned it would rendered typing difficult, but my scores in my typing practice program ([Amphetype](https://code.google.com/p/amphetype/)) did not seem to change very much when I tested them on all subsequent days that I used the treadmill. I suspect that my average WPM went down somewhat, though my statistical analysis indicated it fell slightly (see the [typing section](#typing)). The gear on the treadmill itself began to loosen, which led to the rubber band slipping off the motor or the gear, and I had to stop for a few days while I figured out solutions. (The epoxy was a mistake as it required a 'hardener' I didn't have; a thin nail couldn't be hammered between the gear and treadmill bar as a shim; and I had to let the Gorilla Glue harden for a day before it performed admirably during the test run.) A few days later, the mat began slipping and just stopping, and I discovered that the gear was rotating freely on the treadmill bar - the friction and glue had apparently lost! I lost several days hoping it would dry. It did and seemed to work again, but to help deal with it, I lubricated the underside of the mat with WD-40. It seemed to work

My expectations are that the treadmill will increase how much I sleep, decrease sleep latency, and possibly have a small negative effect on productivity (which may be offset by an improvement in mood and less need to get a daily walk). Subjectively, whenever I use the treadmill, it feels like I can't work on hard material like programming or statistics, and I need to sit down and be still to really focus; I wonder if it is because my head bobbles slightly as I walk, and if a VR solution like an [Oculus Rift](!Wikipedia) might fix the jiggling issue? (If the walking were intense aerobic fitness, I might expect an increase in cognitive abilities or various sorts, but it's not, so I don't expect any effect on Mnemosyne scores.)

# Typing

Fortunately, I had used Amphetype for typing practice for 3 years prior to finding the treadmill, so I could compare my daily treadmill typing sessions to a very long dataseries.

![WPM (top) and accuracy scores (bottom) plotted over time on a time-scaled X-axis with undamped values. The tight group at the far right is the week or two of typing practice while using a treadmill.](/images/zeo/2012-amphetype.png)

The graph looks like WPM (but not Accuracy) may have been damaged, but it's not clear at all: we should do statistics. Amphetype stores the graphed data in a [SQLite](!Wikipedia) database, which after a little tinkering I figured out how to extract the WPM & Accuracy scores:

~~~{.Bash}
$ sqlite3 -batch gwern.db 'SELECT w real, wpm real, accuracy real FROM result;' > ~/stats.txt
~~~

Which gives a file like

~~~
1233502576.01172|70.2471151325281|0.981412639405205
1233502634.48339|80.9762013034008|0.989159891598916
1233502677.26434|74.0623733171948|0.988326848249027
...
~~~

The pipes are delimiters, which I replaced with commas (`tr '|' ','`). The first field is a date-stamp expressed in seconds since the [Unix epoch](!Wikipedia); they can be converted to more readable dates like so:

~~~{.Bash}
$ date --date '@1308320681.44771'
Fri Jun 17 10:24:41 EDT 2011
~~~

I went through the 2870 lines until I found the first treadmill session I did on June 16. After splitting, deleting the date-stamps, and adding a CSV header like `WPM,Accuracy`, I had had 2285 entries for [2012-gwern-amphetype-before.csv](/docs/2012-gwern-amphetype-before.csv) and 585 for [2012-gwern-amphetype-after.csv](/docs/2012-gwern-amphetype-after.csv). Then it is easy to load the CSVs into R and test:

~~~{.R}
before <- read.csv("http://www.gwern.net/docs/2012-gwern-amphetype-before.csv")
before$Treadmill <- 0
after <- read.csv("http://www.gwern.net/docs/2012-gwern-amphetype-after.csv")
after$Treadmill <- 1
amphetype <- rbind(before,after)
l <- lm(cbind(WPM, Accuracy) ~ Treadmill, data=amphetype)

summary(manova(l))
            Df Pillai approx F num Df den Df Pr(>F)
Treadmill    1 0.0556     84.4      2   2867 <2e-16

summary(l)
Response WPM :

Coefficients:
            Estimate Std. Error t value Pr(>|t|)
(Intercept)   82.343      0.195   422.2   <2e-16
Treadmill      5.216      0.432    12.1   <2e-16

Response Accuracy :

Coefficients:
            Estimate Std. Error t value Pr(>|t|)
(Intercept) 0.987517   0.000170 5813.22  < 2e-16
Treadmill   0.001610   0.000376    4.28  1.9e-05
~~~

What? Using a treadmill made my average WPM go *up* 5 WPM? And my average accuracy increased 0.001%? And both are highly statistically-significant (not a surprise, given how many entries there were)? What's going on - this is the exact opposite of expected! The key is the low mean of the `before` data: I type much faster than 82 WPM now, more like 90 or 100 WPM. What happened was that I spent 3 years practicing. Given that I was improving, it is wrong to compare the recent treadmill typing data against a low long-run average without any consideration of this trend of increasing WPM. What would be better would be to lop off the first half of the `before` data to get a fairer comparison with `after`, since I began to plateau around then. Redoing the tests:

~~~{.R}
secondHalf <- amphetype[(nrow(amphetype)/2):nrow(amphetype),]
l2 <- lm(cbind(WPM, Accuracy) ~ Treadmill, data=secondHalf)
summary(l2)

Coefficients:
            Estimate Std. Error t value Pr(>|t|)
(Intercept)   85.826      0.315  272.13  < 2e-16
Treadmill      1.733      0.494    3.51  0.00047


Response Accuracy :

Coefficients:
            Estimate Std. Error t value Pr(>|t|)
(Intercept) 0.988951   0.000259 3820.00   <2e-16
Treadmill   0.000176   0.000406    0.43     0.66
~~~

This is more reasonable: only a 2 WPM gain from the treadmill. 2 WPM could be explicable as just a placebo effect: me wanting to justify the time I've sunk into the treadmill and typing practice every day. It's still a little surprising, but the result initially seems solider. (If we drop every score before 2000 instead of 1144, the difference continues to shrink but still favors the treadmill. We have to go to scores 2100-2285 before the treadmill starts to lose, but with 2200-2285 the treadmill wins!) Accuracy seems largely unaffected. Better yet, we can model the linear progress of my WPM over time and test for a variation that way:

~~~{.R}
amphetype$Nth <- 1:nrow(amphetype)
summary(lm(cbind(WPM, Accuracy) ~ Nth + Treadmill, data=amphetype))
Response WPM :

Coefficients:
            Estimate Std. Error t value Pr(>|t|)
(Intercept) 77.06152    0.37071  207.88   <2e-16
Nth          0.00462    0.00028   16.49   <2e-16
Treadmill   -1.41533    0.57651   -2.45    0.014

Response Accuracy :

Coefficients:
             Estimate Std. Error t value Pr(>|t|)
(Intercept)  9.86e-01   3.35e-04 2938.81  < 2e-16
Nth          1.63e-06   2.54e-07    6.44  1.4e-10
Treadmill   -7.34e-04   5.22e-04   -1.41     0.16
~~~

This is more as expected: so walking on the treadmill cost me -1.5WPM in typing speed, and a day of practice correlates with +0.004WPM (and so a full month of practice would be worth 0.12WPM).
Having reached diminishing returns, I decided to stop typing practice.

# Treadmill effect on Spaced repetition performance: randomized experiment

> It has been claimed that doing spaced repetition review while on a walking treadmill improves memory performance. I did a randomized experiment August 2013 - May 2014 and found that using a treadmill damaged my recall performance.

## Background

[Starting in 2010](http://blog.sethroberts.net/category/walking-and-learning/), Seth Roberts claimed that he found his [Anki](!Wikipedia "Anki (software)") flashcard reviews (for [spaced repetition](Spaced repetition)) to be easier & better when he did them while using his treadmill, and offers some just-so evolutionary psychology theorizing that walking may cue knowledge absorption in a "thirst for knowledge".
He doesn't offer any hard data, but he does [quote some data](http://blog.sethroberts.net/2012/09/05/new-treadmill-catalyzes-learning-results/) from a [2012 presentation by Jeremy Howard](http://vimeo.com/40265872 "Jeremy Howard - Language Acquisition Performance"), who claims a 5% review error-rate while walking and 8% while not-walking, and to be "40% faster [at learning]"; a near-halving of lower grades is certainly an effect to be reckoned with and well worthwhile.

An effect strikes me as plausible: flashcard review does not require fine motor skills or (too) difficult thinking, and the walking might well wake one up if nothing else.
And it would be convenient if it were true, since spaced repetition on one's treadmill would be two birds with one stone.

But on the other hand, the walking might be a distraction from the work of recall and damage real performance, much like how many students claim playing music while studying "helps them focus" which is dubious (eg [Perham & Sykora 2012](/docs/dnb/2012-perham.pdf "Disliked Music can be Better for Performance than Liked Music") found music damaged memory recall, and music you enjoyed was the worst).
Consistent with this, my own experience with treadmills was that it impeded concentration.
And I couldn't help but notice Robert's failure to present hard data: since Anki (like almost all spaced-repetition software), records detailed statistics about flashcard reviews in order to implement the scheduling algorithm, he had access to the data to show some objective performance measurements like whether days on the treadmill increase the average flashcard scores; all he had to do was record his treadmill use and then extract it, which wouldn't take too long to show "a big effect" (a month or two would likely be enough).
But as far as I know, he never made any use of his Anki data.

Having acquired a treadmill, and being a long-time user of Mnemosyne, this seems eminently testable!
I simply randomize whether I do my daily Mnemosyne review before or after getting on the treadmill.
(Unfortunately, I can think of no way to blind treadmill use, so randomization is it.)

One concern, prompted by the [2013 Lewis meditation](Lewis meditation) results, is that there may be time-of-day effects on flashcard review; I tend to not use the treadmill in the morning (I am not a morning person), so if recall improved in the afternoon, then it might be conflated with the treadmill.
I downloaded the [4GB public Mnemosyne dataset](https://groups.google.com/d/msg/mnemosyne-proj-users/tPHlkTFVX_4/oF61BF44iQkJ "Mnemosyne data set available") (every Mnemosyne user is offered the option to anonymously submit statistical data about their flashcards) to try to analyze it and estimate fixed effects of time.
The full dataset showed many such effects, so time variables will be included in the analysis.

## Method

Each day I decided to do spaced repetition, I randomly flipped a bit (50-50) in Bash to determine whether I would do it seated or on my treadmill (which is set to 1mph), and recorded whether that day was treadmill-affected after review.
This was done from August 2013 to May 2014.
Eventually I noticed that the experiment was becoming a [trivial inconvenience](http://wiki.lesswrong.com/wiki/Trivial_inconvenience) that was damaging my hard-earned spaced repetition habit, and ended the experiment.
I didn't do a formal power analysis, but my intuition was that this would be enough data to show an effect, especially if the effect was as large as claimed.

The endpoint is the grades given flashcards each day (measuring retrieval of the memory), and the next grade for each flashcard (partially measuring encoding of the same memory), controlling for easiness (a parameter associated with each flashcard by the SRS estimating how hard to remember the flashcard is and when it should next be reviewed), how long since last review, how long spent on each card, day, day of week, hour of day,

## Data

Extract and process:

~~~{.R}
target <- "~/.local/share/mnemosyne/default.db"
library(sqldf)
# .schema log
# CREATE TABLE log(
#         _id integer primary key autoincrement,
#         event_type integer,
#         timestamp integer,
#         object_id text,
#         grade integer,
#         easiness real,
#         acq_reps integer,
#         ret_reps integer,
#         lapses integer,
#         acq_reps_since_lapse integer,
#         ret_reps_since_lapse integer,
#         scheduled_interval integer,
#         actual_interval integer,
#         thinking_time integer,
#         next_rep integer,
#         scheduler_data integer
#     );
grades <- sqldf("SELECT timestamp,object_id,grade,easiness,thinking_time,actual_interval,(SELECT grade FROM log AS log2 WHERE log2.object_id = log.object_id AND log2.timestamp > log.timestamp ORDER BY log2.timestamp DESC LIMIT 1) AS grade_future FROM log WHERE event_type==9;",
                dbname=target,
                method = c("integer", "factor","integer","numeric","integer","integer", "integer"))
grades$timestamp <- as.POSIXct(grades$timestamp, origin = "1970-01-01", tz = "EST")
grades$thinking_time.log <- log1p(grades$thinking_time); grades$thinking_time <- NULL
colnames(grades) <- c("Timestamp", "ID", "Grade", "Easiness", "Interval.length", "Grade.future", "Thinking.time.log")
## extract the temporal covariates from the timestamp
grades$WeekDay <- as.factor(weekdays(grades$Timestamp))
grades$Hour    <- as.factor(as.numeric(format(grades$Timestamp, "%H")))
grades$Date    <- as.Date(grades$Timestamp)
## select data from during the experiment
treadmill <- grades[grades$Date > as.Date("2013-08-22") &
                    grades$Date < as.Date("2014-06-01"),]

## code which days' review was done on the treadmill
treadmill$Treadmill <- FALSE
treadmillDates <- as.Date(c("2013-08-25", "2013-08-26", "2013-08-28", "2013-09-14", "2013-09-27",
                            "2013-10-14", "2013-11-09", "2013-11-10", "2013-11-14", "2013-11-29",
                            "2013-12-05", "2013-12-07", "2014-01-29", "2014-02-10", "2014-02-15",
                            "2014-02-25", "2014-02-28", "2014-03-04", "2014-03-05", "2014-03-07",
                            "2014-03-09", "2014-03-19", "2014-03-19", "2014-03-24", "2014-03-25",
                            "2014-03-26", "2014-04-03", "2014-04-22", "2014-05-01", "2014-05-05",
                            "2014-05-06", "2014-05-28", "2014-05-29", "2014-05-31"))
for (i in 1:length(treadmillDates)) { treadmill[treadmill$Date==treadmillDates[i],]$Treadmill <- TRUE; }
## serialize clean CSV for analysis
write.csv(treadmill, "~/wiki/docs/spacedrepetition/2014-05-31-mnemosyne-treadmill.csv", row.names=FALSE)
~~~

## Analysis
### Exploratory

~~~{.R}
treadmill <- read.csv("http://www.gwern.net/docs/spacedrepetition/2014-05-31-mnemosyne-treadmill.csv")
summary(treadmill)
#               Timestamp                         ID           Grade            Easiness
# 2013-11-26 19:24:44:   2   JdjSf1pppya0onAIPxTQH2:   7   Min.   :2.00000   Min.   :1.30000
# 2013-11-26 22:22:12:   2   2UiZC5RXFG8BnuCvMwtrHm:   6   1st Qu.:4.00000   1st Qu.:1.43625
# 2013-12-01 18:21:49:   2   8IbavAIp51TfEZBImDfUL8:   6   Median :4.00000   Median :1.92900
# 2013-12-01 18:22:04:   2   BuMaMeubP2hb1ZbPeKZirj:   6   Mean   :3.77776   Mean   :1.87486
# 2013-08-23 22:56:28:   1   C3IyssfGfLfdgkIjNu3jKN:   6   3rd Qu.:4.00000   3rd Qu.:2.16275
# 2013-08-23 22:56:36:   1   I55jUu4zlCsrT5CGnCYOJ4:   6   Max.   :5.00000   Max.   :3.00000
# (Other)            :5844   (Other)               :5817
# Interval.length      Grade.future     Thinking.time.log        WeekDay          Hour
# Min.   :        0   Min.   :0.00000   Min.   :0.0000000   Friday   : 577   Min.   : 9.0000
# 1st Qu.: 26306332   1st Qu.:4.00000   1st Qu.:0.0000000   Monday   : 711   1st Qu.:15.0000
# Median : 44806694   Median :4.00000   Median :0.0000000   Saturday : 857   Median :17.0000
# Mean   : 44591080   Mean   :3.72783   Mean   :0.0391548   Sunday   : 869   Mean   :17.1727
# 3rd Qu.: 64373024   3rd Qu.:4.00000   3rd Qu.:0.0000000   Thursday :1034   3rd Qu.:20.0000
# Max.   :102203789   Max.   :5.00000   Max.   :4.0253517   Tuesday  :1021   Max.   :23.0000
#                     NA's   :5031                          Wednesday: 785
#         Date      Treadmill
# 2013-09-25: 254   Mode :logical
# 2014-02-10: 171   FALSE:2695
# 2014-02-28: 163   TRUE :3159
# 2013-11-09: 162   NA's :0
# 2013-11-14: 155
# 2014-04-22: 145
# (Other)   :4804

## graphing all 5854 reviews is unreadable, so summarize by day & throw out outliers
daily <- aggregate(Grade ~ Date + Treadmill, treadmill, mean)
daily <- daily[order(daily$Date),]
daily <- daily[daily$Grade>=3 & daily$Grade<=4,]
library(ggplot2)
qplot(Date, Grade, color=Treadmill, size=I(5), data=daily)
~~~~

![Mnemosyne spaced-repetition flashcard reviews, averaged by day, colored by whether reviewed while using a walking treadmill or not](/images/spaced-repetition-2014-05-31-mnemosyne-treadmill-dailyaverage.png)

### Tests

Because there's only 4 possible responses in the dataset (2/3/4/5) & they don't look like a normal distribution (even with _n_=5853), my analysis preference is for an [ordinal logistic regression](!Wikipedia "Ordered logit") which captures that structure; on the other hand, a linear model is easier to work with and it is a lot of data.
And because my earlier analysis of the ~50m response Mnemosyne dataset confirmed that there are meaningful hour-of-day and day-of-week effects, I'll want to include those as covariates.
(I was originally going to include card ID as a random-effects variable to reflect the easiness of each card and help reduce the unpredictability of grades; but the most any card had been reviewed during the experiment was 7 times, so the possible gain was limited, and when an analysis with card IDs as a variable took >2 hours to run and still hadn't finished, I decided to simply use Mnemosyne's internal estimate of "easiness".)
I'll first check with a U-test that any effect isn't being completely driven by the covariates.

~~~{.R}
wilcox.test(Grade ~ Treadmill, conf.int=TRUE, data=treadmill)
    Wilcoxon rank sum test with continuity correction

data:  Grade by Treadmill
W = 4363405, p-value = 0.01796
alternative hypothesis: true location shift is not equal to 0
95 percent confidence interval:
 -5.93488865e-05  4.90689572e-05
sample estimates:
difference in location
        5.43849586e-05
~~~

So there's a difference between the groups.
What difference?
I want to look for an effect on the grades given each day, but also an effect on the *next* grade at the next review of flashcards which are affected (or not) by treadmill use, which is tricky because the first grade for flashcard A is an excellent predictor of its next grade (if I graded a flashcard '4', then probably its next grade will be a '4' too).
So `Grade` is both being predicted by the variables but also is a predictor for `Grade.future`.
There's 3 ways I can think of to approach this:

1. estimate `Grade` and `Grade.future` in completely separate regressions; `Grade.future` does not appear in the first regression estimating `Grade`, and in the second one, `Grade.future ~ Grade`
2. treat it as a multivariate multiple regression problem and not try to use `Grade` to predict `Grade.future`
3. improve on #1 and use simultaneous equations: a path model or [structural equation modeling](!Wikipedia)

    The downside of this is that SEMs, while applicable here and an extremely powerful family of techniques, are notoriously difficult to understand or use.
    I am not certain that my attempt to use it for this problem is correct.

I'll present all 3 since they seem to agree.

Separate regressions:

~~~{.R}
summary(lm(Grade ~ Treadmill + Easiness + Interval.length + Thinking.time.log + WeekDay + Hour, data=treadmill))
## Coefficients:
##                       Estimate   Std. Error  t value   Pr(>|t|)
## (Intercept)        2.80677e+00  6.34044e-02 44.26780 < 2.22e-16
## TreadmillTRUE     -5.10778e-02  1.49802e-02 -3.40970 0.00065475
## Easiness           6.03135e-01  1.74181e-02 34.62681 < 2.22e-16
## Interval.length    1.37417e-09  3.10530e-10  4.42522 9.8095e-06
## Thinking.time.log -7.11363e-02  3.09461e-02 -2.29872 0.02155611
## WeekDayMonday     -7.39220e-02  3.16516e-02 -2.33549 0.01955131
## WeekDaySaturday   -1.42952e-01  3.10946e-02 -4.59732 4.3697e-06
## WeekDaySunday     -2.29438e-02  3.07093e-02 -0.74713 0.45501697
## WeekDayThursday   -4.96342e-02  2.93847e-02 -1.68912 0.09125006
## WeekDayTuesday    -4.78373e-02  2.99313e-02 -1.59824 0.11004403
## WeekDayWednesday  -1.03122e-01  3.14425e-02 -3.27971 0.00104523
## Hour              -7.36549e-03  2.35632e-03 -3.12584 0.00178166
##
## Residual standard error: 0.560091 on 5842 degrees of freedom
## Multiple R-squared:  0.178135,   Adjusted R-squared:  0.176587
summary(lm(Grade.future ~ Grade + Treadmill + Easiness + Interval.length + Thinking.time.log + WeekDay + Hour, data=treadmill))
## Coefficients:
##                       Estimate   Std. Error  t value   Pr(>|t|)
## (Intercept)        4.06756e-01  2.27547e-01  1.78757  0.0742200
## Grade              2.40430e-01  3.31083e-02  7.26192 8.9652e-13
## TreadmillTRUE     -3.38867e-03  3.88392e-02 -0.08725  0.9304954
## Easiness           8.75420e-01  6.95734e-02 12.58269 < 2.22e-16
## Interval.length    2.46084e-08  4.00242e-09  6.14837 1.2281e-09
## Thinking.time.log  2.86484e-01  1.55767e-01  1.83918  0.0662539
## WeekDayMonday      2.38570e-02  8.51907e-02  0.28004  0.7795162
## WeekDaySaturday    2.90015e-02  8.25291e-02  0.35141  0.7253727
## WeekDaySunday     -1.44319e-03  7.16955e-02 -0.02013  0.9839451
## WeekDayThursday    4.10939e-03  7.99399e-02  0.05141  0.9590147
## WeekDayTuesday    -1.32259e-02  8.16232e-02 -0.16204  0.8713175
## WeekDayWednesday   6.06417e-02  8.87476e-02  0.68331  0.4946093
## Hour               1.90015e-02  6.03937e-03  3.14627  0.0017141
##
## Residual standard error: 0.529701 on 810 degrees of freedom
##   (5031 observations deleted due to missingness)
## Multiple R-squared:  0.412783,   Adjusted R-squared:  0.404084
~~~

Multivariate:

~~~{.R}
summary(lm(cbind(Grade, Grade.future) ~ Treadmill + Easiness + Interval.length + Thinking.time.log + WeekDay + Hour, data=treadmill))
# Grade:
## ...Coefficients:
##                       Estimate   Std. Error  t value   Pr(>|t|)
## (Intercept)        2.78720e+00  2.20601e-01 12.63457 < 2.22e-16
## TreadmillTRUE     -1.71331e-01  4.07513e-02 -4.20430 2.9103e-05
## Easiness           8.33584e-01  6.77357e-02 12.30642 < 2.22e-16
## Interval.length   -1.38508e-08  4.21703e-09 -3.28449 0.00106550
## Thinking.time.log -2.64515e-01  1.64946e-01 -1.60365 0.10918153
## WeekDayMonday     -4.32958e-01  8.90653e-02 -4.86113 1.4016e-06
## WeekDaySaturday   -4.38449e-01  8.61660e-02 -5.08843 4.4891e-07
## WeekDaySunday     -2.56739e-01  7.55042e-02 -3.40033 0.00070594
## WeekDayThursday   -4.50507e-01  8.32957e-02 -5.40853 8.3666e-08
## WeekDayTuesday    -3.09444e-01  8.58852e-02 -3.60299 0.00033374
## WeekDayWednesday  -4.07119e-01  9.30340e-02 -4.37602 1.3665e-05
## Hour              -1.80859e-02  6.37381e-03 -2.83754 0.00465974
##
## Residual standard error: 0.561802 on 811 degrees of freedom
##   (5031 observations deleted due to missingness)
## Multiple R-squared:  0.48334,    Adjusted R-squared:  0.476332
# Grade.future:
## ...Coefficients:
##                       Estimate   Std. Error  t value   Pr(>|t|)
## (Intercept)        1.07688e+00  2.14528e-01  5.01978 6.3617e-07
## TreadmillTRUE     -4.45816e-02  3.96293e-02 -1.12497   0.260936
## Easiness           1.07584e+00  6.58709e-02 16.33255 < 2.22e-16
## Interval.length    2.12782e-08  4.10093e-09  5.18864 2.6787e-07
## Thinking.time.log  2.22887e-01  1.60405e-01  1.38953   0.165052
## WeekDayMonday     -8.02389e-02  8.66132e-02 -0.92640   0.354511
## WeekDaySaturday   -7.64148e-02  8.37937e-02 -0.91194   0.362071
## WeekDaySunday     -6.31709e-02  7.34254e-02 -0.86034   0.389855
## WeekDayThursday   -1.04206e-01  8.10024e-02 -1.28645   0.198652
## WeekDayTuesday    -8.76254e-02  8.35206e-02 -1.04915   0.294423
## WeekDayWednesday  -3.72417e-02  9.04726e-02 -0.41164   0.680716
## Hour               1.46531e-02  6.19833e-03  2.36404   0.018312
##
## Residual standard error: 0.546335 on 811 degrees of freedom
##   (5031 observations deleted due to missingness)
## Multiple R-squared:  0.374552,   Adjusted R-squared:  0.366069
~~~

SEM (using [lavaan](http://lavaan.ugent.be/)):

~~~{.R}
library(lavaan)
Mnemo.model <- '
                Grade ~ Treadmill + Easiness + Interval.length + Thinking.time.log + WeekDay + Hour
                Grade.future ~ Grade + Treadmill + Easiness + Interval.length + Thinking.time.log + WeekDay + Hour
               '
Mnemo.fit <- sem(model = Mnemo.model, data = treadmill)
summary(Mnemo.fit)
## ...                Estimate  Std.err  Z-value  P(>|z|)
## Regressions:
##   Grade ~
##     Treadmill        -0.169
##     Easiness          0.832
##     Intervl.lngth    -0.000
##     Thinkng.tm.lg    -0.289
##     WeekDay          -0.027
##     Hour             -0.007
##   Grade.future ~
##     Grade             0.238
##     Treadmill        -0.000
##     Easiness          0.877
##     Intervl.lngth     0.000
##     Thinkng.tm.lg     0.288
##     WeekDay           0.001
##     Hour              0.018
##
## Variances:
##     Grade             0.324
##     Grade.future      0.277
~~~

In each of the 3 approaches, the estimated effect of treadmill usage on my Mnemosyne scores that day was negative but after incorporating the negative effect of poorer recall  that day, there did not seem to be additional damage above and beyond that.

## Conclusion

While the result seems highly likely to be true for me, I don't know how well it might generalize to other people.
For example, perhaps more fit people can use a treadmill without harm and the negative effect is due to the treadmill usage tiring & distracting me; I try to walk 2 miles a day, but that's not much compared to some people.

Given this harmful impact, I will avoid doing spaced repetition on my treadmill in the future, and given this & the typing result, will relegate any computer+treadmill usage to non-intellectually-demanding work like watching movies.

<!--
# Appendix: time-varying spaced repetition performance
## Personal

Extract all my data:

~~~{.Bash}
sqlite3 -batch ~/.local/share/mnemosyne/default.db "SELECT timestamp,object_id,easiness,grade FROM log WHERE event_type==9;" | tr '|' ',' > 2014-05-31-gwern-mnemosyne.csv
~~~

~~~{.R}
mnemosyne <- read.csv("2014-05-31-gwern-mnemosyne.csv", header=FALSE, col.names=c("Date", "ID", "Easiness", "Grade"), colClasses=c("integer", "factor", "numeric", "integer"))
mnemosyne$Date <- as.POSIXct(mnemosyne$Date, origin = "1970-01-01", tz = "UTC")
mnemosyne$Year <- as.factor(as.Date(mnemosyne$Date, "%Y"))
mnemosyne$Month <- as.factor(months(mnemosyne$Date))
mnemosyne$WeekDay <- as.factor(weekdays(mnemosyne$Date))
mnemosyne$Day    <- as.factor(as.Date(mnemosyne$Date))
mnemosyne$Hour <- as.factor(as.Date(mnemosyne$Date, "%H"))
mnemosyne <- mnemosyne[order(mnemosyne$ID),]

nrow(mnemosyne)
# [1] 141699

summary(mnemosyne)
#       Date                                   ID            Easiness        Grade
#  Min.   :2009-05-31 23:06:25.00   088b40ad.inv:    44   Min.   :1.30   Min.   :0.00
#  1st Qu.:2009-12-17 04:08:26.50   e8764710    :    40   1st Qu.:1.78   1st Qu.:3.00
#  Median :2010-08-04 16:41:04.00   27fc28b3    :    38   Median :2.05   Median :4.00
#  Mean   :2010-12-07 05:30:08.64   86b870ac    :    38   Mean   :1.99   Mean   :3.64
#  3rd Qu.:2011-08-25 02:38:16.50   1644a7c7    :    36   3rd Qu.:2.24   3rd Qu.:4.00
#  Max.   :2014-05-31 23:44:07.00   7b0e88b5    :    36   Max.   :3.29   Max.   :5.00
#                                   (Other)     :141467
#          Year             Month            WeekDay              Day                 Hour
#  2009-07-13:   779   July    :17729   Friday   :19942   2009-07-13:   779   2009-07-13:   779
#  2009-12-26:   767   August  :16296   Monday   :22064   2009-12-26:   767   2009-12-26:   767
#  2009-07-19:   717   December:13449   Saturday :16467   2009-07-19:   717   2009-07-19:   717
#  2009-07-22:   683   June    :13165   Sunday   :20894   2009-07-22:   683   2009-07-22:   683
#  2009-08-09:   653   January :12218   Thursday :20438   2009-08-09:   653   2009-08-09:   653
#  2009-12-27:   648   November:11023   Tuesday  :19911   2009-12-27:   648   2009-12-27:   648
#  (Other)   :137452   (Other) :57819   Wednesday:21983   (Other)   :137452   (Other)   :137452


library(ordinal)
c1 <- clm(ordered(Grade) ~ Hour + WeekDay + Month + Year + Easiness, data=mnemosyne); summary(c1)

Warning message:
(2) Model is nearly unidentifiable: very large eigenvalue
 - Rescale variables?
In addition: Absolute and relative convergence criteria were met
formula: ordered(Grade) ~ Hour + WeekDay + Month + Year + Easiness
data:    mnemosyne

 link  threshold nobs   logLik     AIC       niter max.grad cond.H
 logit flexible  141699 -122137.75 244369.51 8(0)  2.42e-07 2.0e+12

Coefficients:
                  Estimate Std. Error z value Pr(>|z|)
Hour1            -3.62e-02   4.16e-02   -0.87  0.38427
Hour2             6.39e-02   4.05e-02    1.58  0.11481
Hour3             1.41e-01   4.00e-02    3.51  0.00044
Hour4             3.60e-01   4.34e-02    8.28  < 2e-16
Hour5             1.11e-01   4.77e-02    2.33  0.01966
Hour6            -1.56e-01   5.13e-02   -3.04  0.00237
Hour7             2.68e-01   5.60e-02    4.79  1.7e-06
Hour8             2.46e-01   5.60e-02    4.40  1.1e-05
Hour9            -1.33e-02   5.68e-02   -0.23  0.81424
Hour10            2.47e-01   4.72e-02    5.23  1.7e-07
Hour11            3.92e-01   4.59e-02    8.55  < 2e-16
Hour12           -1.08e-01   7.70e-02   -1.40  0.16188
Hour13            1.34e-01   4.48e-02    2.99  0.00279
Hour14            1.84e-01   3.91e-02    4.71  2.5e-06
Hour15            1.35e-02   3.83e-02    0.35  0.72363
Hour16            6.32e-02   3.87e-02    1.63  0.10274
Hour17            2.20e-02   3.69e-02    0.60  0.55021
Hour18            8.62e-02   3.82e-02    2.26  0.02390
Hour19           -1.89e-01   4.09e-02   -4.62  3.9e-06
Hour20           -1.06e-01   4.05e-02   -2.61  0.00905
Hour21           -1.44e-02   4.06e-02   -0.36  0.72194
Hour22           -1.86e-01   4.59e-02   -4.06  4.9e-05
Hour23           -2.78e-02   4.12e-02   -0.67  0.49990
WeekDayMonday    -7.13e-03   2.19e-02   -0.33  0.74439
WeekDaySaturday  -4.45e-02   2.36e-02   -1.88  0.05969
WeekDaySunday    -2.94e-02   2.22e-02   -1.32  0.18527
WeekDayThursday   4.04e-02   2.25e-02    1.80  0.07180
WeekDayTuesday   -5.39e-02   2.24e-02   -2.40  0.01624
WeekDayWednesday  1.02e-03   2.19e-02    0.05  0.96275
MonthAugust      -2.49e-01   3.14e-02   -7.92  2.4e-15
MonthDecember    -2.68e-01   3.05e-02   -8.78  < 2e-16
MonthFebruary     2.43e-02   3.30e-02    0.74  0.46185
MonthJanuary     -1.48e-01   3.13e-02   -4.73  2.2e-06
MonthJuly        -2.43e-01   3.22e-02   -7.55  4.5e-14
MonthJune        -3.71e-01   3.01e-02  -12.36  < 2e-16
MonthMarch        6.60e-02   3.34e-02    1.98  0.04792
MonthMay         -2.04e-01   3.22e-02   -6.33  2.5e-10
MonthNovember    -5.09e-02   3.18e-02   -1.60  0.10867
MonthOctober      9.00e-02   3.33e-02    2.70  0.00695
MonthSeptember    1.48e-02   3.30e-02    0.45  0.65311
Year              8.20e-04   1.55e-05   53.03  < 2e-16
Easiness          1.51e+00   1.71e-02   88.03  < 2e-16

Threshold coefficients:
    Estimate Std. Error z value
0|1    6.003      0.339    17.7
1|2    9.845      0.245    40.1
2|3   13.129      0.243    53.9
3|4   13.967      0.244    57.3
4|5   18.751      0.248    75.7



# install.packages("lme4")
library(lme4)
lmr <- lmer(Grade ~ Hour + WeekDay + (1|ID), data=mnemosyne); lmr

lmr1 <- lmer(Grade ~ (1:ID) + (1|Hour:WeekDay) + (1|WeekDay), data=mnemosyne)
lmr2 <- lmer(Grade ~ (1:ID) + (1|WeekDay:Hour) + (1|Hour), data=mnemosyne)
lmr3 <- lmer(Grade ~ (1:ID) + (1|Hour) + (1|WeekDay), data=mnemosyne)
lmr4 <- lmer(Grade ~ (1:ID) + (1|WeekDay), data=mnemosyne)
lmr5 <- lmer(Grade ~ (1:ID) + (1|Hour), data=mnemosyne)
lmr6 <- lmer(Grade ~ (1|Hour) + (1|WeekDay), data=mnemosyne)
lmr7 <- lmer(Grade ~ (1|Hour), data=mnemosyne)
lmr8 <- lmer(Grade ~ (1|WeekDay), data=mnemosyne)
anova(lmr1, lmr2, lmr3, lmr4, lmr5, lmr6, lmr7, lmr8)
...
     Df    AIC    BIC  logLik deviance   Chisq Chi Df Pr(>Chisq)
lmr4  3 315209 315238 -157601   315203
lmr5  3 314817 314846 -157405   314811  391.60      0     <2e-16
lmr7  3 314817 314846 -157405   314811    0.00      0          1
lmr8  3 315209 315238 -157601   315203    0.00      0          1
lmr1  4 313076 313115 -156534   313068 2134.91      1     <2e-16
lmr2  4 313071 313111 -156532   313063    4.22      0     <2e-16
lmr3  4 314802 314841 -157397   314794    0.00      0          1
lmr6  4 314802 314841 -157397   314794    0.00      0          1

# lmr2 fits the best:
lmr; ranef(lmr2)
Linear mixed model fit by REML ['lmerMod']
Formula: Grade ~ (1:ID) + (1 | WeekDay:Hour) + (1 | Hour)
   Data: mnemosyne

REML criterion at convergence: 313070

Random effects:
 Groups       Name        Variance Std.Dev.
 WeekDay:Hour (Intercept) 0.02200  0.1483
 Hour         (Intercept) 0.00312  0.0559
 Residual                 0.58263  0.7633
Number of obs: 136006, groups: WeekDay:Hour, 168; Hour, 24

Fixed effects:
            Estimate Std. Error t value
(Intercept)   3.6009     0.0164     220
$`WeekDay:Hour`
             (Intercept)
Friday:0       -0.019139
Friday:1        0.066000
Friday:2        0.127930
Friday:3       -0.030641
Friday:4       -0.003555
Friday:5        0.050270
Friday:6       -0.069348
Friday:7        0.162819
Friday:8        0.111000
Friday:9       -0.095142
Friday:10      -0.302438
Friday:11      -0.109022
Friday:12       0.062432
Friday:13      -0.191936
Friday:14       0.080181
Friday:15       0.056169
Friday:16       0.019640
Friday:17       0.060872
Friday:18       0.121200
Friday:19       0.021702
Friday:20      -0.070333
Friday:21       0.010426
Friday:22       0.184549
Friday:23       0.034788
Monday:0       -0.050514
Monday:1       -0.028257
Monday:2        0.044377
Monday:3        0.039661
Monday:4        0.195395
Monday:5        0.084555
Monday:6        0.245055
Monday:7        0.012922
Monday:8       -0.026822
Monday:9        0.090738
Monday:10       0.058359
Monday:11       0.079431
Monday:12       0.078798
Monday:13      -0.065937
Monday:14      -0.008352
Monday:15      -0.071668
Monday:16      -0.112114
Monday:17       0.035863
Monday:18       0.073842
Monday:19       0.118506
Monday:20       0.072537
Monday:21      -0.018688
Monday:22      -0.281828
Monday:23       0.043099
Saturday:0      0.036154
Saturday:1     -0.068238
Saturday:2     -0.060102
Saturday:3      0.130476
Saturday:4      0.093435
Saturday:5      0.032539
Saturday:6     -1.030752
Saturday:7     -0.070630
Saturday:8     -0.200564
Saturday:9      0.063551
Saturday:10     0.110013
Saturday:11     0.004704
Saturday:12    -0.634920
Saturday:13     0.109141
Saturday:14    -0.031036
Saturday:15     0.083492
Saturday:16     0.058052
Saturday:17    -0.001440
Saturday:18     0.053168
Saturday:19    -0.129243
Saturday:20    -0.049725
Saturday:21     0.052595
Saturday:22     0.030970
Saturday:23     0.089661
Sunday:0        0.077668
Sunday:1        0.002151
Sunday:2        0.036547
Sunday:3       -0.101526
Sunday:4       -0.093471
Sunday:5       -0.285501
Sunday:6        0.219535
Sunday:7        0.043141
Sunday:8        0.120761
Sunday:9       -0.104879
Sunday:10      -0.044698
Sunday:11      -0.173190
Sunday:12       0.135313
Sunday:13       0.085895
Sunday:14       0.046830
Sunday:15      -0.027498
Sunday:16       0.028319
Sunday:17      -0.113491
Sunday:18       0.021524
Sunday:19       0.037930
Sunday:20       0.043320
Sunday:21      -0.069593
Sunday:22       0.074461
Sunday:23       0.059064
Thursday:0      0.097109
Thursday:1     -0.022386
Thursday:2     -0.035211
Thursday:3      0.100196
Thursday:4     -0.012246
Thursday:5     -0.124873
Thursday:6      0.269351
Thursday:7     -0.253772
Thursday:8      0.031430
Thursday:9     -0.044216
Thursday:10     0.025595
Thursday:11     0.144850
Thursday:12    -0.245026
Thursday:13     0.063981
Thursday:14     0.026730
Thursday:15     0.058664
Thursday:16     0.166390
Thursday:17     0.066198
Thursday:18     0.013504
Thursday:19    -0.157871
Thursday:20    -0.055170
Thursday:21     0.077850
Thursday:22    -0.030607
Thursday:23     0.026882
Tuesday:0      -0.175450
Tuesday:1       0.103698
Tuesday:2      -0.050102
Tuesday:3       0.037554
Tuesday:4       0.011223
Tuesday:5       0.057910
Tuesday:6      -0.155696
Tuesday:7      -0.039166
Tuesday:8       0.064975
Tuesday:9      -0.010484
Tuesday:10     -0.076896
Tuesday:11      0.064807
Tuesday:12     -0.005010
Tuesday:13     -0.079948
Tuesday:14      0.037390
Tuesday:15      0.075767
Tuesday:16      0.106249
Tuesday:17      0.071065
Tuesday:18      0.035418
Tuesday:19      0.022454
Tuesday:20      0.069751
Tuesday:21     -0.035432
Tuesday:22     -0.070137
Tuesday:23     -0.188515
Wednesday:0    -0.016837
Wednesday:1    -0.052541
Wednesday:2     0.031597
Wednesday:3    -0.016883
Wednesday:4     0.095349
Wednesday:5     0.082828
Wednesday:6    -0.385014
Wednesday:7     0.128185
Wednesday:8    -0.074648
Wednesday:9    -0.083151
Wednesday:10    0.195809
Wednesday:11    0.072926
Wednesday:12   -0.007923
Wednesday:13    0.058538
Wednesday:14   -0.035893
Wednesday:15   -0.073958
Wednesday:16    0.076137
Wednesday:17    0.128695
Wednesday:18    0.026047
Wednesday:19    0.091466
Wednesday:20    0.058831
Wednesday:21    0.068955
Wednesday:22   -0.017855
Wednesday:23    0.013263

$Hour
   (Intercept)
0   -7.240e-03
1    6.061e-05
2    1.349e-02
3    2.255e-02
4    4.061e-02
5   -1.452e-02
6   -1.287e-01
7   -2.342e-03
8    3.709e-03
9   -2.606e-02
10  -4.862e-03
11   1.199e-02
12  -8.748e-02
13  -2.877e-03
14   1.644e-02
15   1.433e-02
16   4.864e-02
17   3.517e-02
18   4.893e-02
19   7.016e-04
20   9.824e-03
21   1.222e-02
22  -1.568e-02
23   1.111e-02



effects <- ranef(lmr2)$`WeekDay:Hour`
lmr1DayHours <- data.frame(Day=sapply(strsplit(rownames(effects), ":"),  function (x) {x[1]}),
                           Hour=as.integer(sapply(strsplit(rownames(effects), ":"),  function (x) {x[2]})),
                           Effect=effects[1:nrow(effects),])
qplot(Day, Hour, color=Effect, data=lmr1DayHours) + scale_colour_gradient(low="black", high="white")

http://i.imgur.com/6wyR9QZ.png
-->
<!--

I extract the data as before:

    $ sqlite3 -batch ./mnemosyne-stats/logs.db "SELECT timestamp,object_id,grade FROM log WHERE event==9;" | tr '|' ',' > ~/mnemosyne-all.csv
    $ wc mnemosyne-all.csv
      47794669   47794669 1114023396 mnemosyne-all.csv
    $ R
    R> install.packages("biglm")

The `biglm` package offers an *incremental* linear model function: you can read in a million rows, 'add' them to a `biglm` object, read in another million rows and so on. Since I can fit 1 million rows in RAM but not 48 million rows, this works great:

    library(biglm)

    m <- file("mnemosyne-all.csv", open="rt")

    get <- function(filepath) {
        chunk <- read.csv(filepath, nrows=2000000, header=FALSE, col.names=c("Date", "ID", "Grade"), colClasses=c("integer", "factor", "numeric"))
        chunk$Date <- as.POSIXct(chunk$Date, origin = "1970-01-01", tz = "UTC")
        chunk$WeekDay <- as.factor(weekdays(chunk$Date))
        chunk$Hour <- as.factor(as.numeric(format(chunk$Date, "%H")))
        return(chunk)
        }

    frml <- Grade ~ Hour + WeekDay

    # create a seed to update with fresh data in the loop
    chunk1 <- get(m)
    bl <- biglm(frml, chunk1)

    while (isOpen(m)) {
        chunk <- get(m)
        bl <- update(bl, chunk)
    }
    summary(bl)
    closeAllConnections()

    ...
    Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) :
      contrasts can be applied only to factors with 2 or more levels
    Calls: update ... model.matrix -> model.matrix.default -> contrasts<-
    R> # It errors out because I didn't figure out how to handle reading to the end of the file
    R> summary(bl)
    Large data regression model: biglm(frml, chunk1)
    Sample size =  47794669
                     Coef (95%  CI) SE p
    (Intercept)       2.8  2.8  2.8  0 0
    Hour1             0.0  0.0  0.0  0 0
    Hour2             0.0  0.0  0.0  0 0
    Hour3            -0.1 -0.1  0.0  0 0
    Hour4            -0.1 -0.1 -0.1  0 0
    Hour5            -0.2 -0.2 -0.2  0 0
    Hour6            -0.3 -0.3 -0.3  0 0
    Hour7            -0.1 -0.1 -0.1  0 0
    Hour8             0.1  0.1  0.1  0 0
    Hour9             0.2  0.2  0.2  0 0
    Hour10            0.3  0.3  0.3  0 0
    Hour11            0.3  0.3  0.3  0 0
    Hour12            0.3  0.3  0.3  0 0
    Hour13            0.2  0.2  0.2  0 0
    Hour14            0.2  0.2  0.2  0 0
    Hour15            0.2  0.2  0.2  0 0
    Hour16            0.1  0.1  0.1  0 0
    Hour17            0.1  0.1  0.1  0 0
    Hour18            0.1  0.1  0.1  0 0
    Hour19            0.0  0.0  0.1  0 0
    Hour20            0.0  0.0  0.0  0 0
    Hour21            0.0  0.0  0.0  0 0
    Hour22            0.0  0.0  0.0  0 0
    Hour23            0.0  0.0  0.0  0 0
    WeekDayMonday     0.0  0.0  0.0  0 0
    WeekDaySaturday   0.0  0.0  0.0  0 0
    WeekDaySunday     0.0  0.0  0.0  0 0
    WeekDayThursday   0.0  0.0  0.0  0 0
    WeekDayTuesday    0.0  0.0  0.0  0 0
    WeekDayWednesday  0.0  0.0  0.0  0 0

But hopefully 47,794,669 (48m) flashcard reviews is enough. So, pulling out the interesting coefficients - all the weekdays drop out as irrelevant - we get:

    06            -0.3
    05            -0.2
    03            -0.1
    04            -0.1
    07            -0.1
    08             0.1
    16             0.1
    17             0.1
    18             0.1
    09             0.2
    13             0.2
    14             0.2
    15             0.2
    10             0.3
    11             0.3
    12             0.3

(We can ignore the p-values & confidence intervals, since at this sample scale, they're all going to be zero & point-values.) No apparent pattern when sorted by size, but the pattern jumps out when we graph by hour:

    plot(c(0,0,-0.1,-0.1,-0.2,-0.3,-0.1,0.1,0.2,0.3,0.3,0.3,0.2,0.2,0.2,0.1,0.1,0.1,0,0,0,0,0))

http://i.imgur.com/sum3toZ.png

We get a beautiful-looking circadian rhythm: peak performance at noon, crappy performance in early morning, declining performance over the day into evening. I'm actually impressed at the effect sizes here: if you compare reviewing at noon vs reviewing at 6 AM, that's a difference of 0.6 - on a 1-5 scale where most grades are a 3 or 4! If this is reflecting actual memory performance and not some sort of response bias varying by time (like being too pessimistic when you're up too early/late)

That's only about retrieval, though. I wonder if late at night (==near bedtime) would be best for subsequent recalls, but I'm not sure how to analyze that.

This doesn't tell us how hour & day may combine like in my previous multilevel model. So let's rerun with:

    frml <- Grade ~ Hour * WeekDay

This will use up ~4x more RAM while running, BTW, so you may need to reduce how many rows you tell `read.csv` to read in. The results:

    R> summary(bl)
    Large data regression model: biglm(frml, chunk1)
    Sample size =  47794669
                            Coef (95%  CI) SE   p
    (Intercept)              2.8  2.8  2.8  0 0.0
    Hour1                    0.0  0.0  0.0  0 0.0
    Hour2                    0.0  0.0  0.0  0 0.0
    Hour3                    0.0  0.0  0.0  0 0.0
    Hour4                   -0.1 -0.1 -0.1  0 0.0
    Hour5                   -0.2 -0.2 -0.2  0 0.0
    Hour6                   -0.3 -0.3 -0.3  0 0.0
    Hour7                    0.0  0.0  0.0  0 0.0
    Hour8                    0.1  0.1  0.1  0 0.0
    Hour9                    0.1  0.1  0.1  0 0.0
    Hour10                   0.3  0.3  0.3  0 0.0
    Hour11                   0.3  0.3  0.3  0 0.0
    Hour12                   0.3  0.3  0.3  0 0.0
    Hour13                   0.2  0.2  0.2  0 0.0
    Hour14                   0.2  0.2  0.2  0 0.0
    Hour15                   0.2  0.2  0.2  0 0.0
    Hour16                   0.1  0.1  0.1  0 0.0
    Hour17                   0.1  0.1  0.1  0 0.0
    Hour18                   0.1  0.1  0.1  0 0.0
    Hour19                   0.0  0.0  0.0  0 0.0
    Hour20                   0.1  0.1  0.1  0 0.0
    Hour21                   0.1  0.0  0.1  0 0.0
    Hour22                   0.1  0.1  0.1  0 0.0
    Hour23                   0.0  0.0  0.0  0 0.0
    WeekDayMonday            0.0  0.0  0.0  0 0.6
    WeekDaySaturday          0.1  0.0  0.1  0 0.0
    WeekDaySunday            0.0  0.0  0.0  0 0.0
    WeekDayThursday          0.1  0.0  0.1  0 0.0
    WeekDayTuesday           0.0  0.0  0.0  0 0.9
    WeekDayWednesday         0.1  0.1  0.1  0 0.0
    Hour1:WeekDayMonday      0.0  0.0  0.0  0 0.0
    Hour2:WeekDayMonday      0.0 -0.1  0.0  0 0.0
    Hour3:WeekDayMonday      0.0  0.0  0.0  0 0.0
    Hour4:WeekDayMonday      0.0  0.0  0.0  0 0.4
    Hour5:WeekDayMonday      0.0  0.0  0.0  0 0.0
    Hour6:WeekDayMonday      0.1  0.1  0.1  0 0.0
    Hour7:WeekDayMonday      0.0 -0.1  0.0  0 0.0
    Hour8:WeekDayMonday      0.1  0.1  0.2  0 0.0
    Hour9:WeekDayMonday      0.3  0.2  0.3  0 0.0
    Hour10:WeekDayMonday     0.1  0.1  0.1  0 0.0
    Hour11:WeekDayMonday     0.0  0.0  0.0  0 0.0
    Hour12:WeekDayMonday     0.0  0.0  0.0  0 0.0
    Hour13:WeekDayMonday     0.1  0.1  0.1  0 0.0
    Hour14:WeekDayMonday     0.0  0.0  0.1  0 0.0
    Hour15:WeekDayMonday     0.0  0.0  0.0  0 0.0
    Hour16:WeekDayMonday     0.1  0.1  0.1  0 0.0
    Hour17:WeekDayMonday     0.0  0.0  0.0  0 0.1
    Hour18:WeekDayMonday     0.1  0.0  0.1  0 0.0
    Hour19:WeekDayMonday     0.1  0.1  0.1  0 0.0
    Hour20:WeekDayMonday     0.1  0.0  0.1  0 0.0
    Hour21:WeekDayMonday     0.1  0.1  0.1  0 0.0
    Hour22:WeekDayMonday     0.0  0.0  0.0  0 0.0
    Hour23:WeekDayMonday     0.0  0.0  0.0  0 0.0
    Hour1:WeekDaySaturday   -0.1 -0.1 -0.1  0 0.0
    Hour2:WeekDaySaturday   -0.1 -0.1 -0.1  0 0.0
    Hour3:WeekDaySaturday   -0.1 -0.1 -0.1  0 0.0
    Hour4:WeekDaySaturday    0.0  0.0  0.0  0 0.3
    Hour5:WeekDaySaturday    0.0  0.0  0.0  0 0.0
    Hour6:WeekDaySaturday    0.1  0.1  0.1  0 0.0
    Hour7:WeekDaySaturday   -0.2 -0.2 -0.2  0 0.0
    Hour8:WeekDaySaturday    0.0  0.0  0.0  0 0.3
    Hour9:WeekDaySaturday   -0.1 -0.1 -0.1  0 0.0
    Hour10:WeekDaySaturday  -0.1 -0.1 -0.1  0 0.0
    Hour11:WeekDaySaturday  -0.1 -0.1 -0.1  0 0.0
    Hour12:WeekDaySaturday  -0.1 -0.1 -0.1  0 0.0
    Hour13:WeekDaySaturday   0.0  0.0  0.0  0 0.0
    Hour14:WeekDaySaturday   0.0  0.0  0.1  0 0.0
    Hour15:WeekDaySaturday   0.0  0.0  0.0  0 0.1
    Hour16:WeekDaySaturday   0.0  0.0  0.0  0 0.0
    Hour17:WeekDaySaturday   0.0  0.0  0.0  0 0.9
    Hour18:WeekDaySaturday   0.0  0.0  0.0  0 0.4
    Hour19:WeekDaySaturday   0.0  0.0  0.0  0 0.0
    Hour20:WeekDaySaturday  -0.1 -0.1 -0.1  0 0.0
    Hour21:WeekDaySaturday  -0.1 -0.1 -0.1  0 0.0
    Hour22:WeekDaySaturday  -0.1 -0.1 -0.1  0 0.0
    Hour23:WeekDaySaturday  -0.1 -0.1 -0.1  0 0.0
    Hour1:WeekDaySunday     -0.1 -0.1  0.0  0 0.0
    Hour2:WeekDaySunday      0.0  0.0  0.0  0 0.0
    Hour3:WeekDaySunday      0.0  0.0  0.0  0 0.1
    Hour4:WeekDaySunday      0.0  0.0  0.0  0 0.0
    Hour5:WeekDaySunday      0.0  0.0  0.0  0 0.0
    Hour6:WeekDaySunday      0.1  0.1  0.1  0 0.0
    Hour7:WeekDaySunday     -0.1 -0.1 -0.1  0 0.0
    Hour8:WeekDaySunday      0.0  0.0  0.0  0 0.1
    Hour9:WeekDaySunday      0.1  0.0  0.1  0 0.0
    Hour10:WeekDaySunday     0.0  0.0  0.1  0 0.0
    Hour11:WeekDaySunday    -0.1 -0.1 -0.1  0 0.0
    Hour12:WeekDaySunday     0.0 -0.1  0.0  0 0.0
    Hour13:WeekDaySunday     0.0  0.0  0.0  0 0.0
    Hour14:WeekDaySunday     0.1  0.1  0.1  0 0.0
    Hour15:WeekDaySunday     0.1  0.1  0.1  0 0.0
    Hour16:WeekDaySunday     0.1  0.1  0.1  0 0.0
    Hour17:WeekDaySunday     0.0  0.0  0.0  0 0.0
    Hour18:WeekDaySunday     0.0  0.0  0.0  0 0.1
    Hour19:WeekDaySunday     0.1  0.0  0.1  0 0.0
    Hour20:WeekDaySunday     0.0  0.0  0.0  0 0.0
    Hour21:WeekDaySunday    -0.1 -0.1  0.0  0 0.0
    Hour22:WeekDaySunday    -0.1 -0.1 -0.1  0 0.0
    Hour23:WeekDaySunday     0.0  0.0  0.0  0 0.0
    Hour1:WeekDayThursday   -0.1 -0.1  0.0  0 0.0
    Hour2:WeekDayThursday   -0.1 -0.1 -0.1  0 0.0
    Hour3:WeekDayThursday   -0.1 -0.1  0.0  0 0.0
    Hour4:WeekDayThursday    0.0  0.0  0.0  0 0.0
    Hour5:WeekDayThursday   -0.1 -0.1  0.0  0 0.0
    Hour6:WeekDayThursday    0.0 -0.1  0.0  0 0.0
    Hour7:WeekDayThursday   -0.1 -0.2 -0.1  0 0.0
    Hour8:WeekDayThursday    0.1  0.0  0.1  0 0.0
    Hour9:WeekDayThursday    0.0  0.0  0.0  0 0.0
    Hour10:WeekDayThursday   0.0  0.0  0.0  0 0.1
    Hour11:WeekDayThursday   0.0 -0.1  0.0  0 0.0
    Hour12:WeekDayThursday   0.0 -0.1  0.0  0 0.0
    Hour13:WeekDayThursday   0.0  0.0  0.0  0 0.8
    Hour14:WeekDayThursday   0.0  0.0  0.0  0 0.0
    Hour15:WeekDayThursday   0.0  0.0  0.0  0 0.0
    Hour16:WeekDayThursday   0.0  0.0  0.0  0 0.0
    Hour17:WeekDayThursday   0.0  0.0  0.0  0 0.4
    Hour18:WeekDayThursday   0.0 -0.1  0.0  0 0.0
    Hour19:WeekDayThursday   0.0  0.0  0.0  0 0.0
    Hour20:WeekDayThursday  -0.1 -0.1  0.0  0 0.0
    Hour21:WeekDayThursday   0.0 -0.1  0.0  0 0.0
    Hour22:WeekDayThursday  -0.1 -0.1 -0.1  0 0.0
    Hour23:WeekDayThursday  -0.1 -0.1 -0.1  0 0.0
    Hour1:WeekDayTuesday     0.0  0.0  0.0  0 0.0
    Hour2:WeekDayTuesday     0.0  0.0  0.0  0 0.2
    Hour3:WeekDayTuesday     0.0 -0.1  0.0  0 0.0
    Hour4:WeekDayTuesday     0.0  0.0  0.0  0 0.0
    Hour5:WeekDayTuesday     0.0  0.0  0.0  0 0.1
    Hour6:WeekDayTuesday     0.1  0.1  0.1  0 0.0
    Hour7:WeekDayTuesday     0.1  0.1  0.1  0 0.0
    Hour8:WeekDayTuesday     0.1  0.1  0.2  0 0.0
    Hour9:WeekDayTuesday     0.1  0.1  0.1  0 0.0
    Hour10:WeekDayTuesday    0.0  0.0  0.0  0 0.6
    Hour11:WeekDayTuesday    0.0  0.0  0.0  0 0.0
    Hour12:WeekDayTuesday    0.0  0.0  0.0  0 0.0
    Hour13:WeekDayTuesday    0.1  0.1  0.1  0 0.0
    Hour14:WeekDayTuesday    0.0  0.0  0.0  0 0.0
    Hour15:WeekDayTuesday    0.0  0.0  0.0  0 0.3
    Hour16:WeekDayTuesday    0.0  0.0  0.0  0 0.0
    Hour17:WeekDayTuesday    0.0  0.0  0.0  0 0.5
    Hour18:WeekDayTuesday    0.0  0.0  0.0  0 0.6
    Hour19:WeekDayTuesday    0.1  0.0  0.1  0 0.0
    Hour20:WeekDayTuesday    0.0  0.0  0.0  0 0.5
    Hour21:WeekDayTuesday    0.0  0.0  0.0  0 0.8
    Hour22:WeekDayTuesday    0.0  0.0  0.0  0 0.0
    Hour23:WeekDayTuesday    0.0  0.0  0.1  0 0.0
    Hour1:WeekDayWednesday  -0.1 -0.1 -0.1  0 0.0
    Hour2:WeekDayWednesday  -0.1 -0.1 -0.1  0 0.0
    Hour3:WeekDayWednesday  -0.1 -0.1 -0.1  0 0.0
    Hour4:WeekDayWednesday  -0.1 -0.1 -0.1  0 0.0
    Hour5:WeekDayWednesday  -0.1 -0.1  0.0  0 0.0
    Hour6:WeekDayWednesday  -0.1 -0.2 -0.1  0 0.0
    Hour7:WeekDayWednesday  -0.2 -0.2 -0.2  0 0.0
    Hour8:WeekDayWednesday   0.0 -0.1  0.0  0 0.0
    Hour9:WeekDayWednesday   0.0  0.0  0.0  0 0.2
    Hour10:WeekDayWednesday  0.0 -0.1  0.0  0 0.0
    Hour11:WeekDayWednesday  0.0 -0.1  0.0  0 0.0
    Hour12:WeekDayWednesday -0.1 -0.1 -0.1  0 0.0
    Hour13:WeekDayWednesday  0.0 -0.1  0.0  0 0.0
    Hour14:WeekDayWednesday -0.1 -0.1  0.0  0 0.0
    Hour15:WeekDayWednesday -0.1 -0.1  0.0  0 0.0
    Hour16:WeekDayWednesday  0.0  0.0  0.0  0 0.0
    Hour17:WeekDayWednesday -0.1 -0.1 -0.1  0 0.0
    Hour18:WeekDayWednesday -0.1 -0.1 -0.1  0 0.0
    Hour19:WeekDayWednesday -0.1 -0.1 -0.1  0 0.0
    Hour20:WeekDayWednesday -0.1 -0.1 -0.1  0 0.0
    Hour21:WeekDayWednesday -0.1 -0.1 -0.1  0 0.0
    Hour22:WeekDayWednesday -0.1 -0.1 -0.1  0 0.0
    Hour23:WeekDayWednesday -0.1 -0.1  0.0  0 0.0

So, we get very similar values as before for the hours of the day on their own. This time, we actually do get day of week effects for Wednesday, Thursday, and Saturday:

                            Coef
    WeekDaySaturday          0.1
    WeekDayThursday          0.1
    WeekDayWednesday         0.1

And we get a pile of interactions:

    Hour6:WeekDayMonday      0.1
    Hour8:WeekDayMonday      0.1
    Hour9:WeekDayMonday      0.3
    Hour10:WeekDayMonday     0.1
    Hour13:WeekDayMonday     0.1
    Hour16:WeekDayMonday     0.1
    Hour18:WeekDayMonday     0.1
    Hour19:WeekDayMonday     0.1
    Hour20:WeekDayMonday     0.1
    Hour21:WeekDayMonday     0.1

    Hour6:WeekDayTuesday     0.1
    Hour7:WeekDayTuesday     0.1
    Hour8:WeekDayTuesday     0.1
    Hour9:WeekDayTuesday     0.1
    Hour13:WeekDayTuesday    0.1
    Hour19:WeekDayTuesday    0.1

    Hour1:WeekDayWednesday  -0.1
    Hour2:WeekDayWednesday  -0.1
    Hour3:WeekDayWednesday  -0.1
    Hour4:WeekDayWednesday  -0.1
    Hour5:WeekDayWednesday  -0.1
    Hour6:WeekDayWednesday  -0.1
    Hour7:WeekDayWednesday  -0.2
    Hour12:WeekDayWednesday -0.1
    Hour14:WeekDayWednesday -0.1
    Hour15:WeekDayWednesday -0.1
    Hour17:WeekDayWednesday -0.1
    Hour18:WeekDayWednesday -0.1
    Hour19:WeekDayWednesday -0.1
    Hour20:WeekDayWednesday -0.1
    Hour21:WeekDayWednesday -0.1
    Hour22:WeekDayWednesday -0.1
    Hour23:WeekDayWednesday -0.1

    Hour1:WeekDayThursday   -0.1
    Hour2:WeekDayThursday   -0.1
    Hour3:WeekDayThursday   -0.1
    Hour5:WeekDayThursday   -0.1
    Hour7:WeekDayThursday   -0.1
    Hour8:WeekDayThursday    0.1
    Hour20:WeekDayThursday  -0.1
    Hour22:WeekDayThursday  -0.1
    Hour23:WeekDayThursday  -0.1

    Hour1:WeekDaySaturday   -0.1
    Hour2:WeekDaySaturday   -0.1
    Hour3:WeekDaySaturday   -0.1
    Hour6:WeekDaySaturday    0.1
    Hour7:WeekDaySaturday   -0.2
    Hour9:WeekDaySaturday   -0.1
    Hour10:WeekDaySaturday  -0.1
    Hour11:WeekDaySaturday  -0.1
    Hour12:WeekDaySaturday  -0.1
    Hour20:WeekDaySaturday  -0.1
    Hour21:WeekDaySaturday  -0.1
    Hour22:WeekDaySaturday  -0.1
    Hour23:WeekDaySaturday  -0.1

    Hour1:WeekDaySunday     -0.1
    Hour6:WeekDaySunday      0.1
    Hour7:WeekDaySunday     -0.1
    Hour9:WeekDaySunday      0.1
    Hour11:WeekDaySunday    -0.1
    Hour14:WeekDaySunday     0.1
    Hour15:WeekDaySunday     0.1
    Hour16:WeekDaySunday     0.1
    Hour19:WeekDaySunday     0.1
    Hour21:WeekDaySunday    -0.1
    Hour22:WeekDaySunday    -0.1

I don't really understand these estimates. For example, why would 6 AM be terrible in general, but be helpful on Sundays?
-->
